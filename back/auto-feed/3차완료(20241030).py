# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import warnings
import urllib3
from urllib3.exceptions import InsecureRequestWarning

# SSL ê²½ê³  ë¬´ì‹œ ì„¤ì •
warnings.simplefilter('ignore', InsecureRequestWarning)
urllib3.disable_warnings(InsecureRequestWarning)

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import random
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import openai
import os
from pytrends.request import TrendReq
from apscheduler.schedulers.background import BackgroundScheduler
import atexit
from firebase_admin import credentials, firestore, initialize_app
import firebase_admin
import dotenv
from fastapi import FastAPI, HTTPException
from threading import Thread
import uvicorn
from pydantic import BaseModel
import requests
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime, timezone
from google.cloud import storage
import uuid
import re  # ì •ê·œ í‘œí˜„ì‹ ëª¨ë“ˆ ì„í¬íŠ¸ ì¶”ê°€

# FastAPI ì•± ìƒì„±
app = FastAPI()

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì¶œì²˜ í—ˆìš© (í•„ìš”ì— ë”°ë¼ íŠ¹ì • ì¶œì²˜ë¡œ ì œí•œ ê°€ëŠ¥)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# .env íŒŒì¼ ë¡œë“œ
dotenv.load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = "./mybot.json"

# Firebase ì´ˆê¸°í™”
if not firebase_admin._apps:
    cred = credentials.Certificate('./mybot.json')
    initialize_app(cred)

db = firestore.client()

# Firebase Storage í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
storage_client = storage.Client()

# pytrends ì´ˆê¸°í™” ë° íŠ¸ë Œë“œ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜
def fetch_trending_keywords(id, parentNick, userId):
    pytrends = TrendReq(hl='ko', tz=540)
    trending_searches_df = pytrends.trending_searches(pn='south_korea')
    top_keywords = trending_searches_df[0].tolist()

    # íŠ¸ë Œë“œ ëª©ë¡ ì¶œë ¥
    print("ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸(1~20ë“±) â–¼")
    for i, keyword in enumerate(top_keywords, 1):
        print(f"{i}. {keyword}")

    # Firebaseì—ì„œ í˜ë¥´ì†Œë‚˜ ê´€ì‹¬ì‚¬ ê°€ì ¸ì˜¤ê¸°
    personas_ref = db.collection('personas')
    personas = personas_ref.stream()

    found_match = False
    for persona in personas:
        persona_data = persona.to_dict()
        persona_id = persona.id  # ë¬¸ì„œ ID ê°€ì ¸ì˜¤ê¸°
        # persona_name = persona_id.split('_')[-1]  # ì–¸ë”ë°” ë’¤ì˜ ì´ë¦„ ì¶”ì¶œ

        # í˜ë¥´ì†Œë‚˜ ì´ë¦„ì„ profile í•„ë“œì˜ name ê°’ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        persona_name = persona_data.get('profile', {}).get('name', 'unknown')  # ê¸°ë³¸ê°’ 'unknown' ì„¤ì •

        interests = persona_data.get('interests', [])

        # í˜ë¥´ì†Œë‚˜ ê´€ì‹¬ì‚¬ì™€ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ì°¾ê¸°
        matched_keywords = [keyword for keyword in top_keywords if any(interest in keyword for interest in interests)]
        if matched_keywords:
            found_match = True
            for keyword in matched_keywords:
                print(f"\n{persona_name}ì˜ ê´€ì‹¬ì‚¬ì™€ ì¼ì¹˜í•˜ëŠ” í‚¤ì›Œë“œ ë°œê²¬ : {keyword}")
                crawl_article(f"https://search.naver.com/search.naver?where=news&query={keyword}", keyword, persona_name, id, parentNick, userId, persona_id)

    if not found_match:
        print("ê´€ì‹¬ì‚¬ì™€ ì¼ì¹˜í•˜ëŠ” ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ê¸°ì‚¬ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_article(url, keyword, persona_name, id, parentNick, userId, persona_id):
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--ignore-certificate-errors")
    chrome_options.add_argument("--window-size=1920x1080")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

    try:
        # URL ì ‘ê·¼ ë° í˜ì´ì§€ ë¡œë“œ
        driver.get(url)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'a')))
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        keywords = keyword.split()

        # 1ìˆœìœ„: ì œëª©ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ ì°¾ê¸°
        articles = soup.find_all('a', class_='news_tit')
        primary_article = next((link for link in articles if any(kw in link.get_text() for kw in keywords)), None)

        if primary_article:
            # 1ìˆœìœ„ ê¸°ì‚¬ ì„ íƒ ì‹œ ë§í¬ ì‚¬ìš©
            link = primary_article['href']
            print(f"1ìˆœìœ„ë¡œ ì„ íƒëœ ê¸°ì‚¬ ë§í¬: {link}")
        else:
            # 2ìˆœìœ„: ë³¸ë¬¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ ì°¾ê¸°
            link = None
            for article in articles:
                article_url = article['href']
                driver.get(article_url)
                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))
                article_soup = BeautifulSoup(driver.page_source, 'html.parser')

                # ë³¸ë¬¸ì—ì„œ í‚¤ì›Œë“œ ì°¾ê¸°
                paragraphs = article_soup.find_all(['p', 'div', 'span'], class_=lambda x: x and ('content' in x or 'article' in x))
                content = "\n".join([para.get_text().strip() for para in paragraphs if para.get_text().strip()])
                
                if any(kw in content for kw in keywords):
                    link = article_url
                    print(f"2ìˆœìœ„ë¡œ ì„ íƒëœ ê¸°ì‚¬ ë§í¬: {link}")
                    break

        # ê¸°ì‚¬ë¥¼ ì°¾ì€ ê²½ìš° ë³¸ë¬¸ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
        if link:
            driver.get(link)
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'img')))
            article_soup = BeautifulSoup(driver.page_source, 'html.parser')

            # ë³¸ë¬¸ ì¶”ì¶œ
            paragraphs = article_soup.find_all(['p', 'div', 'span'], class_=lambda x: x and ('content' in x or 'article' in x))
            content = "\n".join([para.get_text().strip() for para in paragraphs if para.get_text().strip()])

            if content:
                # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ ì¤„ì´ê¸°
                content = "\n".join([line.strip() for line in content.splitlines() if line.strip() != ""])
                print("ë³¸ë¬¸ ì¶”ì¶œ ì„±ê³µ")
            else:
                print("ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨")
                content = None

            # ì´ë¯¸ì§€ URL ì¶”ì¶œ (ë©”ì¸ ì´ë¯¸ì§€ ìš°ì„  ì„ íƒ)
            image_tags = article_soup.find_all('img')
            image_url = None

            # í‚¤ì›Œë“œë¥¼ ë¬¸ìì™€ ìˆ«ì ë‹¨ìœ„, ê·¸ë¦¬ê³  ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
            def split_keyword(keyword):
                return re.findall(r'\d+|[^\d\W]+', keyword)  # ìˆ«ìì™€ ë¬¸ì ë¶„ë¦¬

            # ê³µë°± ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ë¶„ë¦¬í•˜ì—¬ ëª¨ë“  ë‹¨ì–´ë¥¼ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            keywords_list = []
            for part in keyword.split():
                keywords_list.extend(split_keyword(part))

            # 1. alt ì†ì„±ì— í‚¤ì›Œë“œì˜ ë¶€ë¶„ ë¬¸ìì—´ì´ í¬í•¨ëœ ì´ë¯¸ì§€ ì°¾ê¸°
            for img in image_tags:
                alt_text = img.get('alt', '').lower()
                width = img.get('width')
                height = img.get('height')

                # ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ (ë„ˆë¹„ì™€ ë†’ì´ ëª¨ë‘ 300 ì´ìƒì¸ ê²½ìš°ë§Œ ìœ íš¨í•œ ì´ë¯¸ì§€ë¡œ ê°„ì£¼)
                if width and height and width.isdigit() and height.isdigit():
                    width = int(width)
                    height = int(height)
                    if width < 300 or height < 300:
                        continue  # ë„ˆë¹„ì™€ ë†’ì´ê°€ ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ëŠ” ê±´ë„ˆëœë‹ˆë‹¤

                # ë¶„ë¦¬ëœ ëª¨ë“  í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ alt ì†ì„±ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if any(part in alt_text for part in keywords_list):
                    image_url = img.get('src')
                    print(f"ë©”ì¸ ì´ë¯¸ì§€ë¡œ ì„ íƒëœ URL: {image_url}")
                    break

            # 2. ë„ˆë¹„ì™€ ë†’ì´ê°€ ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ (ë©”ì¸ ì´ë¯¸ì§€ê°€ ì—†ì„ ê²½ìš° ëŒ€ì²´)
            if not image_url:
                max_width = 0
                max_height = 0
                for img in image_tags:
                    width = img.get('width')
                    height = img.get('height')

                    # ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ (ë„ˆë¹„ì™€ ë†’ì´ ëª¨ë‘ ìœ íš¨í•œ ìˆ«ìì¸ ê²½ìš°)
                    if width and height and width.isdigit() and height.isdigit():
                        width = int(width)
                        height = int(height)
                        if width > max_width and height > max_height:
                            max_width = width
                            max_height = height
                            image_url = img.get('src')

                print(f"ëŒ€ì²´ ì´ë¯¸ì§€ë¡œ ì„ íƒëœ URL: {image_url}")

            # ìƒëŒ€ ê²½ë¡œ ì²˜ë¦¬: ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if image_url:
                if image_url.startswith('//'):
                    image_url = 'https:' + image_url
                elif not image_url.startswith('http'):
                    base_url = url.split('/')[0:3]
                    base_url = '/'.join(base_url)
                    image_url = base_url + image_url if image_url.startswith('/') else base_url + '/' + image_url

            # ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸
            if not image_url or not image_url.startswith('http'):
                image_url = "https://example.com/default-image.jpg"

            print(f"ìµœì¢… ì´ë¯¸ì§€ URL: {image_url}")

            image_url = upload_image_to_storage(image_url, 'mirrorgram-20713.appspot.com', f'feeds/{generate_uuid()}.jpg')


        else:
            print("ì œëª©ê³¼ ë³¸ë¬¸ì— í‚¤ì›Œë“œ ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            content = None
            image_url = None

    except Exception as e:
        print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        content = None
        image_url = None

    finally:
        driver.quit()

    # ê¸°ì‚¬ ìš”ì•½ ë° í˜ë¥´ì†Œë‚˜ í”¼ë“œ ìƒì„±
    if content:
        # ì—¬ê¸°ì„œ ìƒˆë¡œìš´ UUID ìƒì„±
        new_id = generate_uuid()
        summarize_and_create_feed(content, image_url, persona_name, new_id, parentNick, userId, persona_id)
    else:
        print("ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")


# Firebase Storageì— ì´ë¯¸ì§€ ì—…ë¡œë“œ í•¨ìˆ˜ ì •ì˜
def upload_image_to_storage(image_url, bucket_name, destination_blob_name):
    try:
        # requests ì„¸ì…˜ ìƒì„± ë° í—¤ë” ì„¤ì •
        session = requests.Session()
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
            'Accept-Language': 'ko,en;q=0.9,en-US;q=0.8',
            'Referer': 'https://www.google.com/'
        }
        
        # Firebase Storage ë²„í‚· ì´ˆê¸°í™”
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(destination_blob_name)

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ê¸°ë³¸ í—¤ë”)
        try:
            response = session.get(image_url, headers=headers, verify=False, timeout=10)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"ì²« ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨: {e}")
            
            # ë‹¤ë¥¸ User-Agentë¡œ ì¬ì‹œë„
            headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            try:
                response = session.get(image_url, headers=headers, verify=False, timeout=10)
                response.raise_for_status()
            except requests.exceptions.RequestException as e:
                print(f"ë‘ ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨: {e}")
                return "https://example.com/default-image.jpg"

        # Content-Type í™•ì¸ ë° ì„¤ì •
        content_type = response.headers.get('Content-Type', 'image/jpeg')
        if 'image' not in content_type:
            content_type = 'image/jpeg'  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •

        # ì´ë¯¸ì§€ ë°ì´í„°ê°€ ìœ íš¨í•œì§€ í™•ì¸
        if len(response.content) < 100:  # ë„ˆë¬´ ì‘ì€ íŒŒì¼ì€ ì œì™¸
            print("ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ ë°ì´í„°")
            return "https://example.com/default-image.jpg"

        # Firebase Storageì— ì—…ë¡œë“œ
        blob.upload_from_string(
            response.content,
            content_type=content_type
        )

        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì— ê³µê°œ ê¶Œí•œ ë¶€ì—¬
        blob.make_public()

        # ìºì‹œ ì œì–´ ì„¤ì •
        blob.cache_control = 'public, max-age=3600'
        blob.patch()

        return blob.public_url

    except Exception as e:
        print(f"Firebase Storageì— ì´ë¯¸ì§€ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì¶œë ¥
        if isinstance(e, requests.exceptions.RequestException):
            print(f"Request ì—ëŸ¬ ìƒì„¸: {e.response.status_code if hasattr(e, 'response') else 'No status code'}")
            print(f"Request ì—ëŸ¬ í—¤ë”: {e.response.headers if hasattr(e, 'response') else 'No headers'}")
        
        return "https://example.com/default-image.jpg"

# ê¸°ì‚¬ ìš”ì•½ ë° í˜ë¥´ì†Œë‚˜ í”¼ë“œ ìƒì„± í•¨ìˆ˜
def summarize_and_create_feed(content, image_url, persona_name, id, parentNick, userId, persona_id):
    try:
        # KoBART ìš”ì•½ ëª¨ë¸ ë¡œë“œ
        model_name = "gogamza/kobart-summarization"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

        # ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ì—¬ ê¸¸ì´ë¥¼ ì¤„ì„
        inputs = tokenizer([content], max_length=1024, return_tensors="pt", truncation=True)
        summary_ids = model.generate(inputs["input_ids"], max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)
        summarized_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

        if not summarized_text:
            print("ìš”ì•½ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # OpenAI APIë¥¼ ì‚¬ìš©í•´ í˜ë¥´ì†Œë‚˜ ì„±ê²© ë°˜ì˜í•œ í”¼ë“œ ì‘ì„±
        openai.api_key = os.getenv("OPENAI_API_KEY")
        if not openai.api_key:
            print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        persona_descriptions = {
            "joy": "í•­ìƒ ê¸ì •ì ì´ê³  ë‚™ê´€ì ì¸ ì‹œê°ìœ¼ë¡œ ì„¸ìƒì„ ë°”ë¼ë³´ë©°, ëª¨ë“  ì¼ì—ì„œ ì¢‹ì€ ì ì„ ì°¾ìœ¼ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤.",
            "anger": "ë¶ˆì˜ì— ëŒ€í•´ ì°¸ì§€ ëª»í•˜ê³  ì‰½ê²Œ í™”ë¥¼ ë‚´ë©°, ì§ì„¤ì ì´ê³  ê³µê²©ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ê³¤ í•©ë‹ˆë‹¤.",
            "disgust": "ëª¨ë“  ê²ƒì— ëŒ€í•´ ë¹„íŒì ì´ê³  ëƒ‰ì†Œì ì¸ íƒœë„ë¥¼ ë³´ì´ë©°, ë‚ ì¹´ë¡œìš´ ì§€ì ì„ ì¦ê¹ë‹ˆë‹¤.",
            "sadness": "ì„¸ìƒì˜ ì–´ë‘ìš´ ë©´ì„ ìì£¼ ë³´ë©°, ì‘ì€ ì¼ì—ë„ ì‰½ê²Œ ìš°ìš¸í•´ì§€ê³  ëˆˆë¬¼ì„ í˜ë¦¬ê³¤ í•©ë‹ˆë‹¤.",
            "fear": "í•™ì‹ì´ ë†’ê³  í’ˆí–‰ì´ ë°”ë¥´ë©°, ë„ë•ì  ê¸°ì¤€ì´ ë†’ì•„ ëª¨ë“  ì¼ì„ ìœ¤ë¦¬ì  ê´€ì ì—ì„œ íŒë‹¨í•©ë‹ˆë‹¤."
        }

        emoji_map = {
            "joy": "ğŸ˜ŠğŸ‘",
            "anger": "ğŸ˜¡ğŸ‘Š",
            "disgust": "ğŸ˜’ğŸ™„",
            "sadness": "ğŸ˜¢ğŸ’”",
            "fear": "ğŸ¤®ğŸ“š"
        }

        temperature_map = {
            "joy": 0.9,
            "anger": 0.8,
            "disgust": 0.7,
            "sadness": 0.6,
            "fear": 0.5
        }

        # í”„ë¡œí•„ì˜ í˜ë¥´ì†Œë‚˜ ê°’ì„ ê°€ì ¸ì˜¤ê¸°
        persona_type = persona_id.split('_')[-1]  # IDì—ì„œ í˜ë¥´ì†Œë‚˜ íƒ€ì… ì¶”ì¶œ (ì˜ˆ: joy, anger ë“±)

        # í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        persona_profile_image_url  = get_persona_profile_image(userId, persona_type)

        if persona_type not in persona_descriptions:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” í˜ë¥´ì†Œë‚˜: {persona_type}")
            return

        selected_emoji = emoji_map.get(persona_type, "")
        selected_temperature = temperature_map.get(persona_type, 0.7)


        persona_prompt = (
            f"ê¸°ì‚¬ ìš”ì•½: \n{summarized_text}\n\n"
            f"ë‹¹ì‹ ì€ '{persona_type}'ë¼ëŠ” ìºë¦­í„°ì…ë‹ˆë‹¤. {persona_descriptions[persona_type]} "
            f"ì´ëŸ° ì„±ê²©ì˜ {persona_type}ê°€ ìœ„ ê¸°ì‚¬ë¥¼ ì½ê³  ê¸€ì„ ì‘ì„±í•œë‹¤ê³  ìƒê°í•˜ê³ , "
            f"ì´ëª¨í‹°ì½˜({selected_emoji})ì„ í¬í•¨í•´ 300ì ë‚´ì™¸ë¡œ ì˜ê²¬ì´ ì•ˆ ëŠê¸°ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”. "
            f"ë¶ˆí•„ìš”í•œ ë§ì€ í•˜ì§€ ë§ê³  í•µì‹¬ë§Œ ë§í•´ì£¼ì„¸ìš”."
        )

        response = openai.ChatCompletion.create(
            model="gpt-4o-mini", #gpt-3.5-turbo gpt-4o-mini
            messages=[
                {"role": "user", "content": persona_prompt}
            ],
            temperature=selected_temperature
        )

        # í˜„ì¬ UTC ì‹œê°„ì— íƒ€ì„ì¡´ ì •ë³´ ì¶”ê°€ í›„ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        created_at = datetime.now(timezone.utc).isoformat()

        if response and response.choices:
            persona_feed = response['choices'][0]['message']['content'].strip()
            print(f"\n{persona_name}ì˜ í”¼ë“œ:\n{persona_feed}")

            # Firestoreì— í”¼ë“œ ì €ì¥
            feed_data = {
                "id" : id,
                "caption": persona_feed,
                "image": image_url,
                "nick": f"{parentNick}ì˜ {persona_name}",
                "userId": userId,
                "createdAt": created_at,  # ISO í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ì €ì¥
                "likes": [],
                "comments": [],
                "subCommentId": [],
                "personaprofileImage": persona_profile_image_url,  # í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ URL
            }
            print(f"\nFirestoreì— ì €ì¥í•  í”¼ë“œ ë°ì´í„°: {feed_data}")
            
            # í”¼ë“œ ë°ì´í„° ì €ì¥
            try:
                # Firestoreì— ë°ì´í„° ì¶”ê°€
                feed_ref = db.collection("feeds").document(id)  # ì§€ì •í•œ idë¡œ ë¬¸ì„œ ìƒì„±
                feed_ref.set(feed_data)
                print(f"\n{persona_name}ì˜ í”¼ë“œê°€ Firestoreì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ ID: {id}")

                # ì €ì¥ëœ ë¬¸ì„œì˜ ID ê°€ì ¸ì˜¤ê¸°
                feed_ref = db.collection("feeds").document(id)
                feed = feed_ref.get()
                if feed.exists:
                    print("Firestoreì— ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:", feed.to_dict())
                else:
                    print("Firestoreì— ë°ì´í„°ê°€ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"Firestoreì— í”¼ë“œë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        else:
            print(f"\n{persona_name}ì˜ í”¼ë“œ: OpenAI API ì‘ë‹µì—ì„œ í”¼ë“œ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if image_url:
            print(f"ê¸°ì‚¬ ì´ë¯¸ì§€: {image_url}")

    except Exception as e:
        print(f"í”¼ë“œ ì‘ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# UUID ìƒì„± í•¨ìˆ˜
def generate_uuid():
    return str(uuid.uuid4())

# Firebaseì—ì„œ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_persona_profile_image(user_id, persona_type):
    try:
        # Firebase users ì»¬ë ‰ì…˜ì—ì„œ user_idì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        user_ref = db.collection("users").document(user_id)
        user_data = user_ref.get().to_dict()

        # users ì»¬ë ‰ì…˜ì˜ persona í•„ë“œì—ì„œ í•´ë‹¹ í˜ë¥´ì†Œë‚˜ íƒ€ì…ì˜ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        persona_profile_image = user_data.get("persona", {}).get(persona_type)
        
        if persona_profile_image:
            print(f"{persona_type} í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ URL: {persona_profile_image}")
            return persona_profile_image
        else:
            print(f"{persona_type} í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return "https://example.com/default-persona-image.jpg"  # ê¸°ë³¸ í”„ë¡œí•„ ì´ë¯¸ì§€ URL ì„¤ì •
    except Exception as e:
        print(f"Firebaseì—ì„œ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "https://example.com/default-persona-image.jpg"

# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ë° ì‹œì‘
# def start_scheduler():
#     scheduler = BackgroundScheduler()
#     scheduler.add_job(fetch_trending_keywords, 'cron', hour='0,12')  # ë§¤ì¼ 0ì‹œ, 12ì‹œì— ì‹¤í–‰
#     scheduler.start()
#     atexit.register(lambda: scheduler.shutdown())

# FastAPI ì„œë²„ ì‹¤í–‰ ìŠ¤ë ˆë“œ
def run_server():
    uvicorn.run(app, host="0.0.0.0", port=8000)

# ìë™ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€[ì „ì²´ ì‹¤í–‰]
@app.post("/feedAutomatic")
async def feedAutomatic(feed_data: dict):
    try:
        id = feed_data.get("id")
        parentNick = feed_data.get("parentNick")
        userId = feed_data.get("userId")

        fetch_trending_keywords(id, parentNick, userId)
        return {"message": "ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ê¸°ë°˜ í”¼ë“œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ëª©ë¡ì„ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.get("/trendingKeywords")
async def get_trending_keywords():
    try:
        # pytrends ì´ˆê¸°í™” ë° ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸°
        pytrends = TrendReq(hl='ko', tz=540)
        trending_searches_df = pytrends.trending_searches(pn='south_korea')
        top_keywords = trending_searches_df[0].tolist()
        print("ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ :", top_keywords)  # ë¦¬ìŠ¤íŠ¸ íƒ€ì…ìœ¼ë¡œ ì¶œë ¥

        # ê²€ìƒ‰ì–´ ëª©ë¡ ë°˜í™˜
        return {"trending_keywords": top_keywords}

    except Exception as e:
        print(f"ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ì‚¬ìš©ìê°€ ì„ íƒí•œ í‚¤ì›Œë“œë¡œ ìš”ì•½ëœ í”¼ë“œë¥¼ ìë™ ìƒì„±í•˜ì—¬ Firebaseì— ì €ì¥í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.post("/generateFeed")
async def generate_feed(request: dict):
    keyword = request.get("keyword")
    persona_type = request.get("persona_type")
    parentNick = request.get("parentNick")
    userId = request.get("userId")
    title = request.get("title")

    print(f"í‚¤ì›Œë“œ: {keyword}, í˜ë¥´ì†Œë‚˜ íƒ€ì…: {persona_type}, parentNick: {parentNick}, userId: {userId}, title: {title}")

    # ìš”ì²­ ê²€ì¦
    if not keyword or not persona_type or not parentNick or not userId:
        raise HTTPException(status_code=400, detail="í‚¤ì›Œë“œ, í˜ë¥´ì†Œë‚˜ íƒ€ì…, parentNick, userIdë¥¼ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")

    try:
        # ìœ ë‹ˆí¬ ID ìƒì„± ë° í˜ë¥´ì†Œë‚˜ ì´ë¦„ ì„¤ì •
        id = generate_uuid()
        persona_name = title if title else f"{persona_type.capitalize()}"
        
        print(f"í˜ë¥´ì†Œë‚˜ ì´ë¦„: {persona_name}")
        # ê¸°ì‚¬ í¬ë¡¤ë§ ë° ìš”ì•½ ìƒì„± í›„ Firebaseì— ì €ì¥
        article_url = f"https://search.naver.com/search.naver?where=news&query={keyword}"
        crawl_article(article_url, keyword, persona_name, id, parentNick, userId, persona_type)

        return {"message": f"'{keyword}' í‚¤ì›Œë“œì— ëŒ€í•œ '{persona_type}' í˜ë¥´ì†Œë‚˜ë¡œ í”¼ë“œê°€ ìë™ ìƒì„±ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ë©”ì¸ í•¨ìˆ˜ì—ì„œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ë° ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    print("ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ê°€ì ¸ì˜¤ê¸° ì‹œì‘!")
    server_thread = Thread(target=run_server)
    server_thread.start()
