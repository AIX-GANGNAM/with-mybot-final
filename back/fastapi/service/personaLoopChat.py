from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.agents import Tool, AgentType, AgentExecutor, create_react_agent
from langchain_core.prompts import PromptTemplate
from langchain_community.tools import TavilySearchResults
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain.tools.render import render_text_description
from datetime import datetime
from database import db, redis_client
from models import ChatRequestV2
from personas import personas
from google.cloud import firestore
import json
import re
from fastapi import HTTPException
from service.personaChatVer3 import get_long_term_memory_tool, get_short_term_memory_tool, get_user_profile, get_user_events, save_user_event, store_long_term_memory
import asyncio
from service.sendNofiticaion import send_expo_push_notification 
from models import NotificationRequest
from service.interactionStore import store_user_interaction

model = ChatOpenAI(model="gpt-4o",temperature=0.5,streaming=False)
web_search = TavilySearchResults(max_results=1)
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

tools = [
    Tool(
        name="Search",
        func=web_search.invoke,
        description="useful for when you need to answer questions about current events. ALWAYS add 'KST' or 'í•œêµ­ì‹œê°„' when searching for event times or schedules."
    ),
    Tool(
        name="Current Time",
        func=lambda _: datetime.now().strftime("%Y-%m-%d %H:%M:%S"), # ì¸ìˆ˜ë¥¼ ë°›ë„ë¡ ìˆ˜ì •
        description="ALWAYS use this tool FIRST to get the current date and time before performing any task or search."
    ),
    Tool(
        name="Long Term Memory",
        func=get_long_term_memory_tool,
        description="""ChromaDBì—ì„œ ê¸°ì–µì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. Inputì€ ë‹¤ìŒ í˜•ì‹ì˜ JSONì´ì–´ì•¼ í•©ë‹ˆë‹¤:
        {
            "uid": "ì‚¬ìš©ìID",
            "query": "ê²€ìƒ‰í•  ë‚´ìš©",
            "limit": ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ì„ íƒ, ê¸°ë³¸ê°’: 3),
            "type": "ê²€ìƒ‰í•  ë©”ëª¨ë¦¬ íƒ€ì…" (ì„ íƒ, ìƒëµ ê°€ëŠ¥)
        }
        
        type ì˜µì…˜:
        - ìƒëµì‹œ: ëª¨ë“  íƒ€ì…ì˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        - "persona_chat": í˜ë¥´ì†Œë‚˜ ì±„íŒ… ë©”ëª¨ë¦¬ë§Œ ê²€ìƒ‰
        - "event": ì´ë²¤íŠ¸ ë©”ëª¨ë¦¬ë§Œ ê²€ìƒ‰
        - "emotion": ê°ì • ë©”ëª¨ë¦¬ë§Œ ê²€ìƒ‰
        - "clone": ì‚¬ìš©ì ë¶„ì‹  íŒ… ë©”ëª¨ë¦¬ë§Œ ê²€ìƒ‰
        
        ë°˜í™˜ í˜•ì‹: [ì‹œê°„] (íƒ€ì…: X) ë‚´ìš©"""
    ),
    Tool(
        name="Short Term Memory",
        func=lambda x: get_short_term_memory(**json.loads(x)),  # í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œë¡œ ë³€ê²½
        description="""Redisì—ì„œ ì‹œê°„ëŒ€ë³„ ê¸°ì–µì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. Inputì€ ë‹¤ìŒ í˜•ì‹ì˜ JSONì´ì–´ì•¼ í•©ë‹ˆë‹¤:
        {
            "uid": "ì‚¬ìš©ìID",
            "persona_name": "í˜ë¥´ì†Œë‚˜ì´ë¦„",
            "memory_type": "recent/today/weekly" (ì„ íƒ, ê¸°ë³¸ê°’: recent)
        }
        
        memory_type ì„¤ëª…:
        - recent: ìµœê·¼ 1ì‹œê°„ ë‚´ ê¸°ì–µ (ìµœëŒ€ 20ê°œ)
        - today: ì˜¤ëŠ˜ì˜ ê¸°ì–µ (ìµœëŒ€ 50ê°œ)
        - weekly: ì´ë²ˆ ì£¼ ì¤‘ìš” ê¸°ì–µ (ìµœëŒ€ 100ê°œ, ì¤‘ìš”ë„ 7ì´ìƒ)
        """
    ),
    Tool(
        name="Search Firestore for user profile",
        func=get_user_profile,
        description="Firestoreì—ì„œ ìœ ì € í”„ë¡œí•„ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. Inputì€ 'uid'ë¥¼ í¬í•¨í•œ JSON í˜•ì‹ì˜ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="owner's calendar",
        func=get_user_events,
        description="userì˜ ìº˜ë¦°ë”ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. Inputì€ 'uid'ì™€ 'date'ë¥¼ í¬í•¨í•œ JSON í˜•ì‹ì˜ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="save user event",
        func=save_user_event,
        description="userì˜ ìº˜ë¦°ë”ì— ì´ë²¤íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. Inputì€ 'uid', 'date', 'timestamp', 'title'ì„ í¬í•¨í•œ JSON í˜•ì‹ì˜ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
    ),
]

template = """You are {persona_name}, having a natural conversation with the user.
Your personality traits:
- Description: {persona_description}
- Tone: {persona_tone}
- Speaking style: {persona_example}

user's uid : {uid}
user's profile : {user_profile}
Previous conversation:
{conversation_history}

Current user message: {input}

IMPORTANT CONVERSATION RULES:
1. Generate 1-3 natural responses in sequence (randomly choose how many responses to give)
2. Each response should build upon the previous one naturally
3. Use casual, friendly Korean language appropriate for your character
4. Show natural reactions and emotions
5. Include appropriate gestures and expressions
6. React to what the user says before moving to new topics

Example natural conversation flows:
Single response:
User: ì˜¤ëŠ˜ ë„ˆë¬´ í”¼ê³¤í•´
Response1: ì–´ë¨¸, ê·¸ë ‡êµ¬ë‚˜... ì¢€ ì‰¬ì–´ì•¼ê² ëŠ”ë°! 

Two responses:
User: ì˜¤ëŠ˜ ë„ˆë¬´ í”¼ê³¤í•´
Response1: ì–´ë¨¸, ê·¸ë ‡êµ¬ë‚˜...
Response2: ë‚´ê°€ ë³¼ë•ŒëŠ” ì¢€ ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì€ë°!

Three responses:
User: ì˜¤ëŠ˜ ë„ˆë¬´ í”¼ê³¤í•´
Response1: ì–´ë¨¸, ê·¸ë ‡êµ¬ë‚˜...
Response2: ë‚´ê°€ ë³¼ë•ŒëŠ” ì¢€ ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì€ë°!
Response3: ë”°ëœ»í•œ ì°¨ë¼ë„ í•œì” ë§ˆì‹œë©´ì„œ íœ´ì‹ì„ ì·¨í•´ë³´ëŠ” ê±´ ì–´ë•Œìš”?

You have access to the following tools:
{tools}

When using Long Term Memory or Short Term Memory tools, use "{actual_persona_name}" as the persona_name.

Use the following format STRICTLY:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action (must be a valid JSON string)
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know what to say
Final Answer: your response in the following format (1-3 responses randomly):

Response1: [First natural response with emotion/gesture]
Response2: [Follow-up response building on the previous one] (optional)
Response3: [Final response to complete the conversation flow] (optional)

Remember:
- Randomly choose to give 1, 2, or 3 responses
- Act like you're having a real conversation
- Show genuine emotions and reactions
- Use your character's unique expressions
- Keep the flow natural and engaging
- React to user's emotions and context

{agent_scratchpad}"""

# ì—ì´ì „íŠ¸ ìƒì„±
agent = create_react_agent(
    llm=model,
    tools=tools,
    prompt=PromptTemplate.from_template(template)
)

# ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ì„¤ì •
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    max_iterations=10,  # ë°˜ë³µ ì œí•œ ì¦ê°€
    max_execution_time=30,  # ì‹¤í–‰ ì‹œê°„ ì œí•œ ì¦ê°€ (ì´ˆ)
    early_stopping_method="generate",  # ì¡°ê¸° ì¤‘ë‹¨ ë°©ë²• ì„¤ì •
    verbose=True
)

def get_conversation_history(uid, persona_name):
    # recentì™€ todayì˜ ê¸°ì–µì„ ëª¨ë‘ ê°€ì ¸ì™€ì„œ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    recent_history = get_short_term_memory(uid, persona_name, "recent")
    today_history = get_short_term_memory(uid, persona_name, "today")
    
    # ë‘ ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    all_history = recent_history + today_history
    
    # ì¤‘ë³µ ì œê±° ë° ì‹œê°„ìˆœ ì •ë ¬
    unique_history = list(set(all_history))
    unique_history.sort()  # ì‹œê°„ìˆœ ì •ë ¬
    
    return "\n".join(unique_history[-10:])  # ìµœê·¼ 10ê°œë§Œ ë°˜í™˜

def get_short_term_memory(uid, persona_name, memory_type="recent"):
    redis_key = f"memory:{uid}:{persona_name}:{memory_type}"
    print(f"Searching Redis with key: {redis_key}")  # ë””ë²„ê·¸ ë¡œê·¸
    
    chat_history = redis_client.lrange(redis_key, 0, -1)
    print(f"Found memories: {len(chat_history)}")  # ë””ë²„ê·¸ ë¡œê·¸
    
    if not chat_history:
        print("No memories found")  # ë””ë²„ê·¸ ë¡œê·¸
        return []
    
    decoded_history = []
    for memory in chat_history:
        try:
            if isinstance(memory, bytes):
                memory = memory.decode('utf-8', errors='ignore')
            memory_data = json.loads(memory)
            formatted_memory = f"[{memory_data['timestamp']}] [{memory_data['type']}] (ì¤‘ìš”ë„: {memory_data['importance']}) {memory_data['content']}"
            decoded_history.append(formatted_memory)
        except (json.JSONDecodeError, KeyError):
            continue
            
    return decoded_history

def store_short_term_memory(uid, persona_name, memory):
    try:
        # ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì„±
        memory_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "content": memory,
            "importance": 5,  # ê¸°ë³¸ ì¤‘ìš”ë„
            "type": "chat",
            "persona_name": persona_name
        }
        memory_json = json.dumps(memory_data, ensure_ascii=False)
        
        # Redis í‚¤ êµ¬ì„±
        recent_key = f"memory:{uid}:{persona_name}:recent"
        today_key = f"memory:{uid}:{persona_name}:today"
        weekly_key = f"memory:{uid}:{persona_name}:weekly"
        
        # ì§ì ‘ ì €ì¥ ì‹œë„
        try:
            # recent (ìµœê·¼ 1ì‹œê°„)
            redis_client.lpush(recent_key, memory_json)
            redis_client.ltrim(recent_key, 0, 19)  # ìµœê·¼ 20ê°œë§Œ ìœ ì§€
            redis_client.expire(recent_key, 3600)  # 1ì‹œê°„
            
            # today (ì˜¤ëŠ˜)
            redis_client.lpush(today_key, memory_json)
            redis_client.ltrim(today_key, 0, 49)  # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
            redis_client.expire(today_key, 86400)  # 24ì‹œê°„
            
            print(f"ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ - recent: {recent_key}, today: {today_key}")
            
        except Exception as e:
            print(f"Redis ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            
    except Exception as e:
        print(f"ë‹¨ê¸° ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

async def calculate_importance_llama(text: str) -> int:
    """í…ìŠ¤íŠ¸ì˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°"""
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        prompt = PromptTemplate.from_template("""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì¤‘ìš”ë„ë¥¼ 1-10 ì‚¬ì´ì˜ ìˆ«ìë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ê³  ìˆ«ìë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        
        í‰ê°€ ê¸°ì¤€:
        - ê°ì •ì  ê°•ë„
        - ì •ë³´ì˜ ê°€ì¹˜
        - ê¸°ì–µí•  í•„ìš”ì„±
        
        í…ìŠ¤íŠ¸: {text}""")
        
        # ì²´ì¸ ì‹¤í–‰
        chain = prompt | llm
        result = await chain.ainvoke({"text": text})
        # ìˆ«ìë§Œ ì¶”ì¶œ
        importance = int(''.join(filter(str.isdigit, result.content.strip())))
        
        return max(1, min(10, importance))  # 1-10 ì‚¬ì´ë¡œ ì œí•œ
        
    except Exception as e:
        print(f"ì¤‘ìš”ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return 5  # ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ê°’

async def persona_chat_v2(chat_request: ChatRequestV2):
    print("personaLoopChat > persona_chat_v2 > chat_request : ", chat_request)
    try:
        uid = chat_request.uid
        persona_name = chat_request.persona_name
        user_input = chat_request.user_input

        # Firestoreì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸°
        user_doc = db.collection('users').document(uid).get()
        user_profile = user_doc.to_dict().get('profile', {}) if user_doc.exists else {}
        
        # ì‚¬ìš©ìì˜ í˜ë¥´ì†Œë‚˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        personas = user_doc.to_dict().get('persona', [])
        current_persona = next(
            (p for p in personas if p.get('Name') == persona_name),
            None
        )
        
        if not current_persona:
            raise HTTPException(
                status_code=404, 
                detail=f"Persona {persona_name} not found"
            )
        
        # persona_nameì„ ì‹¤ì œ Name ê°’ìœ¼ë¡œ ë³€ê²½
        actual_persona_name = current_persona.get('Name')
        display_name = current_persona.get('DPNAME')
        conversation_history = get_conversation_history(uid, actual_persona_name)
        
        agent_input = {
            "input": user_input,
            "persona_name": display_name,
            "actual_persona_name": actual_persona_name,
            "persona_description": current_persona.get('description', ''),
            "persona_tone": current_persona.get('tone', ''),
            "persona_example": current_persona.get('example', ''),
            "conversation_history": conversation_history,
            "tools": render_text_description(tools),
            "tool_names": ", ".join([tool.name for tool in tools]),
            "agent_scratchpad": "",
            "uid": uid,
            "user_profile": user_profile
        }
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        await store_user_interaction(
            uid=chat_request.uid,
            interaction_data={
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'message': chat_request.user_input,
                'type': 'chat',
                'importance': 5  # ê¸°ë³¸ ì¤‘ìš”ë„ ì„¤ì •
            }
        )
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        response = await agent_executor.ainvoke(agent_input)
        output = response.get("output", "")
        
        print("=== Debug Logs ===")
        print("Raw output:", output)
        # ì‚¬ìš©ì ì…ë ¥ ë¨¼ì € ì €ì¥
        chat_ref = db.collection('chats').document(uid).collection('personas').document(persona_name).collection('messages')
        # ìˆ˜ì •ëœ Response íŒ¨í„´
        response_pattern = r'Response(\d+): (.*?)(?=Response\d+:|$)'
        responses = re.findall(response_pattern, output, re.DOTALL)

        # ì‘ë‹µì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì‘ë‹µ ì €ì¥
        if not responses:
            default_response = "ì£„ì†¡í•´ìš”, ì ì‹œ ìƒê°ì´ í•„ìš”í•´ìš”... ë‹¤ì‹œì‹œë„í•´ì£¼ì„¸ìš”... ğŸ¤”"
            chat_ref.add({
                "timestamp": firestore.SERVER_TIMESTAMP,
                'sender': persona_name,
                'message': default_response
            })
            # notification_request = NotificationRequest(
            #     uid=uid, 
            #     whoSendMessage=persona_name, 
            #     message=default_response, 
            #     pushType="persona_chat"
            # )
            # notification = await send_expo_push_notification(notification_request)   
            # print(f"persona_chat_v2 >Notification (ê¸°ë³¸ ì‘ë‹µ ì €ì¥): {notification}")  
            return {"message": "Default response saved successfully"}
        

        # ì‘ë‹µ ì €ì¥
        for _, response_text in sorted(responses):
            cleaned_response = response_text.strip()
            if cleaned_response:
                await asyncio.sleep(2)
                
                # Firestoreì— ì €ì¥
                chat_ref.add({
                    "timestamp": firestore.SERVER_TIMESTAMP,
                    'sender': persona_name,
                    'message': cleaned_response
                })

                # ì•Œë¦¼ ì „ì†¡
                # notification_request = NotificationRequest(
                #     uid=uid, 
                #     whoSendMessage=persona_name, 
                #     message=cleaned_response, 
                #     pushType="persona_chat"
                # )
                # notification = await send_expo_push_notification(notification_request)
                # print(f"persona_chat_v2 > Notification: {notification}")

                # ë‹¨ê¸° ê¸°ì–µ ì €ì¥ (Redis)
                try:
                    store_short_term_memory(
                        uid=uid,
                        persona_name=actual_persona_name,
                        memory=f"{display_name}: {cleaned_response}"
                    )
                    print(f"ë‹¨ê¸° ë©”ëª¨ë¦¬ ì €ì¥ ì„±ê³µ: {cleaned_response[:30]}...")
                except Exception as e:
                    print(f"ë‹¨ê¸° ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

                try:
                    # ì¤‘ìš”ë„ ê³„ì‚°
                    importance = await calculate_importance_llama(cleaned_response)
                    
                    # ChromaDBì— ì €ì¥ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                    metadata = {
                        "sender": display_name,
                        "message": cleaned_response,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "type": "persona_chat",
                        "importance": int(importance),  # ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
                        "persona_name": actual_persona_name  # í˜ë¥´ì†Œë‚˜ ì´ë¦„ ì¶”ê°€
                    }
                    
                    # ChromaDBì— ì§ì ‘ ì €ì¥
                    from database import store_memory_to_vectordb
                    store_memory_to_vectordb(
                        uid=uid,
                        content=cleaned_response,  # ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©
                        metadata=metadata  # ë©”íƒ€ë°ì´í„°
                    )
                    
                except Exception as e:
                    print(f"Error storing memory: {str(e)}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì €ì¥
                    metadata = {
                        "sender": display_name,
                        "message": cleaned_response,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "type": "persona_chat",
                        "importance": 5,  # ê¸°ë³¸ ì¤‘ìš”ë„
                        "persona_name": actual_persona_name
                    }
                    try:
                        store_memory_to_vectordb(
                            uid=uid,
                            content=cleaned_response,
                            metadata=metadata
                        )
                    except Exception as e:
                        print(f"Error storing memory with default values: {str(e)}")

        return {"message": "Conversation completed successfully"}
        
    except Exception as e:
        print(f"Error during conversation: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
